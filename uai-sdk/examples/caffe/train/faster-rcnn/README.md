# py-faster-rcnn Example
py-faster-rcnn is a real-time object detection methodology with Region Proposal Networks. This example follows https://github.com/rbgirshick/py-faster-rcnn and provides examples to run faster-rcnn training based on UAI Environments(including using UAI gpu docker image and using UAI Train platform)

We present how to run end2end training based on pretrained VGG16 model in this example.

## Setup
You should follow https://github.com/rbgirshick/py-faster-rcnn/README.md to download VOCdevkit and VGG16 model.

UCloud provides basic py-faster-rcnn docker images through uhub.ucloud.cn/uaishare/gpu\_uaitrain\_ubuntu-14.04\_python-2.7.6\_caffe-py-faster-rcnn:v1.0, you can download this docker after register a UCloud account.

The image includes:

  - cudnn6.0+cuda8.0
  - rbgirshick/py-faster-rcnn
  - uai sdk

py-faster-rcnn location in the image: /root/py-faster-rcnn
caffe location in the image: /root/py-faster-rcnn/caffe-fast-rcnn/

## Intro
The entry point of the training progress is tools/train_net.py. We have modified it to run on UAI platforms. All codes are in examples/caffe/train/faster-rcnn/code/ including tools and lib, both are directly copied from 'py-faster-rcnn' with appropreate modification.

## UAI Example
### Prepare for packing training image
Suppose we put every thing in /voc_test/

	$ cd /voc_test/
	$ ls
	$ code base_tool.py data output

  - base_tool.py is copied from uaitrain\_tool
  - code dir contains both lib/ and tools/ code
  - data dir contains necessary data for testing training locally (including VOCdevkit2007 and models)
  - output dir is the target for output

### Preparing codes
We need to do several modifications to the original code from rbgirshick's

  - tools/train\_net.py
  - lib/fast\_rcnn/config.py
  - lib/rpn/anchor\_target\_layer.py

We have already modifed the code for you. All files under code/ are ready to go.

#### Modify tools/train\_net.py
	# L11: import os lib
	import os

	# L53: Add UAI Platform related args, these args are auto-generated by UAI Platform
      parser.add_argument("--num_gpus", type=int, default=1, help="Num of GPUs") 
      parser.add_argument("--work_dir", help="No usage, compatable with other AI Archs") 
      parser.add_argument("--data_dir", help="No usage, compatable with other AI Archs")         
      parser.add_argument("--output_dir", help="No usage, compatable with other AI Archs")  
      parser.add_argument("--log_dir", help="No usage, compatable with other AI Archs")  

	# L84: change python exec dir to let it load training data directly:
	#     1. Change the exec dir
	#     2. make a link from actual data location (should be /data/data/xxx in UAI platform to /root/py-faster-rcnn/
      os.chdir("/root/py-faster-rcnn/")
      imdb_path = os.path.join(args.data_dir, args.imdb_name)                                                                                                  
      target_imdb_path = os.path.join("/root/py-faster-rcnn/", args.imdb_name)                                                                                 
      os.symlink(imdb_path, target_imdb_path)
      
#### Modify lib/fast\_rcnn/config.py
	# L218: Make output dir to /data/output/default/
	#    /data/output is the default output location for UAI platform
      outdir = osp.abspath(osp.join('/data/', 'output/', __C.EXP_DIR, imdb.name))

#### Modify lib/rpn/anchor\_target\_layer.py
	# L127: cast idx to int, as numpy > 1.11 does not support float idx
	bbox_targets[ind, int(start):int(end)] = 	bbox_target_data[ind, 1:]
	bbox_inside_weights[ind, int(start):int(end)] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS

	L166: cast idx to int, as numpy > 1.11 does not support float idx
	fg_inds = npr.choice(fg_inds, size=int(fg_rois_per_this_image), replace=False)

	L177: cast idx to int, as numpy > 1.11 does not support float idx
	bg_inds = npr.choice(bg_inds, size=int(bg_rois_per_this_image), replace=False)

	L184: cast idx to int, as numpy > 1.11 does not support float idx
      labels[int(fg_rois_per_this_image):] = 0

### Preparing data
We should put VOCdevkit2007 data into /voc\_test/data/ and put models (same as rbgirshick/py-faster-rcnn/models/) into /voc\_test/data. Futher we put VGG.v2.caffemodel into /voc\_test/data/models/models/.

	$ ls /voc_test/data
	VOCdevkit2007/
	models/

### Packing the end2end traing image
	$ cd /voc_test/
	$ sudo python base_tool.py pack --public_key=<YOUR_PUB_KEY> \
		--private_key=<YOUR_PRI_KEY> \
		--code_path=./code \
		--mainfile_path=tools/train_net.py \
		--uhub_username=<UHUB_LOGIN_NAME> \
		--uhub_password=<UHUB_LOGIN_PASS> \
		--uhub_registry=<UHUB_REGISTRY> \ 
		--uhub_imagename=caffe-faster-rcnn \
		--internal_uhub=true \
		--test_data_path=/voc_test/data \
		--test_output_path=/voc_test/output \
		--train_params="--solver=/data/data/models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights=/data/data/models/models/VGG16.v2.caffemodel --cfg experiments/cfgs/faster_rcnn_end2end.yml" \
		--self_img=uhub.service.ucloud.cn/uaishare/gpu_uaitrain_ubuntu-14.04_python-2.7.6_caffe-py-faster-rcnn:v1
		
The pack cmd will generate executable docker cmd to run the training

	 sudo nvidia-docker run -it -v /voc_test/data:/data/data -v /voc_test/output:/data/output uhub.ucloud.cn/<YOUR_REGISTRY>/caffe-faster-rcnn:uaitrain /bin/bash -c "cd /data && /usr/bin/python /data/tools/train_net.py --solver=/data/data/models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights=/data/data/models/models/VGG16.v2.caffemodel --cfg experiments/cfgs/faster_rcnn_end2end.yml --num_gpus=1 --work_dir=/data --data_dir=/data/data --output_dir=/data/output --log_dir=/data/output"
	 
### Run on UAI Train Platform
Please see https://docs.ucloud.cn/ai/uai-train/ for more information and contact our sales from ucloud.cn

## Build Your Own Faster-RCNN Docker Image
We provide an example in faster-rcnn/docker/ to show how to build a self-defined faster-rcnn docker image from scratch.