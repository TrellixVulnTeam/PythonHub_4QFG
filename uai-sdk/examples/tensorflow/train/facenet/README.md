# Face Detection Example with FaceNet
This example shows how to use FaceNet to do face recognition training on UCloud AI Train Platform. The example is based on https://github.com/davidsandberg/facenet.

# Setup
You should prepare your own training data. As UAI Train nodes does not provide network access, you should prepare your data locally.

## Intro
The FaceNet example directly use the code in https://github.com/davidsandberg/facenet. We made several modifications to train\_softmax.py and train\_tripletloss.py to make them runnable on UCloud AI Train Platform.

## UAI Example
The example use msceleb dataset. You should download it yourself, or you can use other dataset. 

### FaceNet Algorithm
We made several modifications to train\_softmax.py and train\_tripletloss.py to make them runnable on UAI Train Platform:

1. Add UAI SDK related arguments: --data\_dir, --output\_dir, --work_dir, --log_dir, --num_gpus, these arguments are auto generated by UAI Train Platform, see: https://github.com/ucloud/uai-sdk/blob/master/uaitrain/arch/tensorflow/uflag.py for more details.
2. Modify code to use UAI arguments to locate its training data and output path. 

#### Softmax
We provilde the modified train\_softmax.py under code/train\_softmax.py:

	# L30
	import os

	# L49 Use args.data_dir (/data/data/) as base input data path
	#         data_dir = /data/data/msceleb
	#         lfw_dir = /data/data/lfw_mtcnnpy_160
	#     Use args.output_dir (/data/output) as base output path
	#         models_base_dir = /data/output/<args.models_base_dir>
	data_dir = os.path.join(args.data_dir, args.data_path)
	args.lfw_dir = os.path.join(args.data_dir, args.lfw_dir)
    args.models_base_dir = os.path.join(args.output_dir, args.models_base_dir)

    # L75 Use data_dir as input dataset
    train_set = facenet.get_dataset(data_dir)

    # L495 add --data_path args
    parser.add_argument('--data_path', type=str,
         help='Path to the data directory containing aligned face patches.',
         default='~/datasets/casia/casia_maxpy_mtcnnalign_182_160')

    # L582 ADD UAI Train related args
    parser.add_argument('--work_dir', type=str, default='/data/', help='UAI SDK related.')
    parser.add_argument('--log_dir', type=str, default='/data/data/', help='UAI SDK related.')

    parser.add_argument('--data_dir', type=str, required=True, help='UAI SDK related. The directory where data will be stored.')
    parser.add_argument('--output_dir', type=str, required=True, help='UAI SDK related. The directory where the model will be stored.')
    parser.add_argument('--num_gpus', type=int, default=1, help='UAI SDK related. The number of gpus used.')

#### Triplet-loss
We provilde the modified train\_tripletloss.py under code/train\_tripletloss.py:

	# L31
	import os

	# L48 Use args.data_dir (/data/data/) as base input data path
	#         data_dir = /data/data/msceleb
	#         lfw_dir = /data/data/lfw_mtcnnpy_160
	#     Use args.output_dir (/data/output) as base output path
	#         models_base_dir = /data/output/<args.models_base_dir>
	data_dir = os.path.join(args.data_dir, args.data_path)
	args.lfw_dir = os.path.join(args.data_dir, args.lfw_dir)
    args.models_base_dir = os.path.join(args.output_dir, args.models_base_dir)

    # L70 Use data_dir as input dataset
    train_set = facenet.get_dataset(data_dir)

    # L433 add --data_path args
    parser.add_argument('--data_path', type=str,
         help='Path to the data directory containing aligned face patches.',
         default='~/datasets/casia/casia_maxpy_mtcnnalign_182_160')

    # L488 ADD UAI Train related args
    parser.add_argument('--work_dir', type=str, default='/data/', help='UAI SDK related.')
    parser.add_argument('--log_dir', type=str, default='/data/data/', help='UAI SDK related.')

    parser.add_argument('--data_dir', type=str, required=True, help='UAI SDK related. The directory where data will be stored.')
    parser.add_argument('--output_dir', type=str, required=True, help='UAI SDK related. The directory where the model will be stored.')
    parser.add_argument('--num_gpus', type=int, default=1, help='UAI SDK related. The number of gpus used.')


### Preparation

#### Create Local Test Data Path
In this example, we use msceleb as training data and lfw as eval data. 

We use the decode\_msceleb\_dataset.py to decode the msceleb data (MsCelebV1-Faces-Aligned.tsv). As the original decode\_msceleb\_dataset.py is not compatable with MsCelebV1-Faces-Aligned.tsv now, we have made several modifications to it. The modified code can be found under code/decode\_msceleb\_dataset.py. You can use following cmd to parse msceleb data:

	$ cd PATH_TO_FACENET/code/
	$ python decode_msceleb_dataset.py --tsv_files <PATH_TO_MsCelebV1-Faces-Aligned.tsv> --output_dir <PATH_TO_OUTPUT> --size=182

You should use align/align\_dataset\_mtcnn.py to process the lfw data. (You can follow https://github.com/davidsandberg/facenet/wiki/Classifier-training-of-inception-resnet-v1 to process the lfw data).

We put both msceleb data and lfw into one dir, for example:

    /data/facenet-data/
    |_ msceleb
    |  |_ m.0_0zl
    |  |  |_ 0-FaceId-0.png
    |  |  |_ 1-FaceId-0.png
    |  |  |_ ...
    |  |  |_ 110-FaceId-0.png
    |  |_ m.0_0zy
    |  |_ ...
    |  |_ m.0zx05c9
    |_ lfw_mtcnnpy_160
    |  |_ Aaron_Eckhart
    |  |  |_ Aaron_Eckhart_0001.png
    |  |_ ...
    |  |_ Zydrunas_Ilgauskas

#### Preparing the FaceNet code for UAI Train
You can use the code in facenet/code/ directly

	/data/facenet/
	|_ code
	|  |_ align
	|  |_ calculate_filtering_metrics.py
	|  |_ ...
	|  |_ train_softmax.py 
	|  |_ train_tripletloss.py
	|  |_ ...
	|_ lr-data
	|  |_ learning_rate_retrain_tripletloss.txt
	|  |_ ...
	|  |_ pairs.txt
	|_ facenet.Dockerfile

### Build the Docker images
You should run the docker build under PATH\_TO/facenet

	# cd /data/facenet/
	# sudo docker build -f facenet.Dockerfile -t facenet:test .

### Run the train
#### Softmax
We can simply use the following cmd to run the local test.(GPU version)

    sudo nvidia-docker run -v /data/face-data/:/data/data/ -v /data/output/facenet/:/data/output/ -it facenet:test /bin/bash -c "cd /data&&python train_softmax.py --logs_base_dir logs/facenet --models_base_dir models/facenet/ --data_dir /data/data/ --data_path msceleb/ --image_size 160 --model_def models.inception_resnet_v1 --lfw_dir lfw_mtcnnpy_160/ --learning_rate -1 --optimizer ADAM --max_nrof_epochs 150 --keep_probability 0.4 --random_flip --use_fixed_image_standardization --weight_decay 5e-4 --embedding_size 512 --output_dir=/data/output/ --log_dir=/data/output/ --num_gpus=1 --lfw_distance_metric 1 --lfw_use_flipped_images --lfw_subtract_mean --validation_set_split_ratio 0.01 --validate_every_n_epochs 5 --learning_rate_schedule_file lr-data/learning_rate_schedule_classifier_vggface2.txt --lfw_pairs lr-data/pairs.txt"

**Note: the train data is mapped into /data/data/, the msceleb data is passed as --data\_path msceleb/ and the lfw_dir is passed as --lfw\_dir lfw_mtcnnpy_160/**

Note: lfw\_pairs are put into /data/lr-data/ in Docker image

#### Triplet-loss
	sudo nvidia-docker run -v /data/face-data/:/data/data/ -v /data/output/facenet/:/data/output/ -it facenet:test /bin/bash -c "cd /data&&
	python train_tripletloss.py --logs_base_dir logs/facenet --models_base_dir models/facenet/ --data_dir /data/data/ --data_path msceleb/ --image_size 160 --model_def models.inception_resnet_v1 --lfw_dir lfw_mtcnnpy_160/ --optimizer ADAM --max_nrof_epochs 150 --keep_probability 0.8 --random_crop --random_flip --weight_decay 5e-4 --embedding_size 512 --output_dir=/data/output/ --log_dir=/data/output/ --num_gpus=1 --learning_rate_schedule_file lr-data/learning_rate_schedule_classifier_casia.txt --lfw_pairs lr-data/pairs.txt"

**Note: the train data is mapped into /data/data/, the msceleb data is passed as --data\_path msceleb/ and the lfw_dir is passed as --lfw\_dir lfw_mtcnnpy_160/**

Note: lfw\_pairs are put into /data/lr-data/ in Docker image

## RUN on UAI Train Platform
You can use the same image to run the training on UAI Train Platform. For more details please see https://docs.ucloud.cn/ai/uai-train.